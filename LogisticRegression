import numpy as np
import matplotlib.pyplot as plt
from astropy.table import Table
from sklearn.preprocessing import normalize

x_train = np.loadtxt('X.dat')
y_train = np.loadtxt('Y.dat')
x_test = np.loadtxt('Xtest.dat')
y_test = np.loadtxt('Ytest.dat')
x_train = normalize(np.c_[np.ones(x_train.shape[0]), x_train], axis=0)
x_test = normalize(np.c_[np.ones(x_test.shape[0]), x_test], axis=0)
betas = np.zeros(x_train.shape[1])

def logistic_func(theta, X):
    return float(1) / (1 + np.exp(-X.dot(theta)))

def log_gradient(theta, X, Y):
    first_calc = np.squeeze(Y) - np.exp(X.dot(theta)) / (1 + np.exp(X.dot(theta)))
    final_calc = X.T.dot(first_calc)
    return final_calc

def cost_func(theta, X, Y):
    log_func_v = np.exp(X.dot(theta)) / (1 +np.exp(X.dot(theta)))
    Y = np.squeeze(Y)
    step1 = Y * np.log(log_func_v)
    step2 = (1-Y) * np.log(1 - log_func_v)
    final = step1 + step2
    return np.mean(final)

def grad_asc(theta_values, X, Y, shrinkage, lr=.001):
    cost_iter = []
    cost = cost_func(theta_values, X, Y)
    cost_iter.append([0, cost])
    for i in range(1,1001):
        theta_values = (1 - lr * shrinkage) * theta_values + lr * log_gradient(theta_values, X, Y)
        cost = cost_func(theta_values, X, Y)
        cost_iter.append([i, cost])
    return theta_values, np.array(cost_iter)

def pred_values(theta, X, hard=True):
    pred_prob = logistic_func(theta, X)
    pred_value = np.where(pred_prob >= .5, 1, 0)
    if hard:
        return pred_value
    return pred_prob

lmbda = [0.1, 0.01, 0.001]
trainerror = []
testerror = []
for shrkg in lmbda:
    fitted_values, cost_iterations = grad_asc(betas, x_train, y_train, shrkg, 0.05)
    plt.plot(cost_iterations[300:1000,0], -cost_iterations[300:1000,1], label = shrkg)
    plt.xlabel('iterations')
    plt.ylabel('negative log-likelihood')
    plt.legend(loc=0)
    predicted_y_train = pred_values(fitted_values, x_train)
    trainerror.append(sum(predicted_y_train != y_train) / len(y_train))
    predicted_y_test = pred_values(fitted_values, x_test)
    testerror.append(sum(predicted_y_test != y_test) / len(y_test))
plt.show()
print(Table([lmbda, trainerror, testerror], names=('lambda', 'Train Error', 'Test Error')))
